{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c76b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e0e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tuples(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "      This function reads a JSON file containing intents data and returns a list of tuples\n",
    "      combining intents and corresponding responses.\n",
    "\n",
    "      Args:\n",
    "          filename (str): The path to the JSON file.\n",
    "\n",
    "      Returns:\n",
    "          list: A list of tuples containing intents and responses.\n",
    "    \"\"\"\n",
    "      # Read the JSON file\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "      # Initialize empty list to store tuples\n",
    "    all_I = []\n",
    "\n",
    "      # Loop through each greeting tag\n",
    "    for tag in data:\n",
    "        # Extract greetings and responses\n",
    "        query = tag[\"patterns\"]\n",
    "        responses = tag[\"responses\"]\n",
    "\n",
    "        # Combine patterns and responses into tuples\n",
    "        tuples = list(zip(query, responses))\n",
    "\n",
    "        # Add tuples to the main list\n",
    "        all_I.extend(tuples)\n",
    "\n",
    "    return all_I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8ed99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_query(query, all_data):\n",
    "    processed_query = preprocess_text(query)\n",
    "    #print(processed_query)\n",
    "    #print(\"\\n\\n\")\n",
    "    processed_responses = [preprocess_text(res) for res, _ in all_data]\n",
    "    #print(processed_questions)    \n",
    "\n",
    "    # Calculate Jaccard similarity for each question\n",
    "    similarities = []\n",
    "    for responses in processed_responses:\n",
    "        if responses is not None:\n",
    "\n",
    "            query_set = set(processed_query.split())\n",
    "            responses_set = set(responses.split())\n",
    "            intersection = len(query_set.intersection(responses_set))\n",
    "            union = len(query_set.union(responses_set))\n",
    "            if union != 0:\n",
    "                \n",
    "                similarities.append(intersection / union)  # Jaccard similarity score\n",
    "            #else:\n",
    "               # print(\"I'm sorry, I don't have an answer to that in my system\")\n",
    "    # Find the question with the highest similarity\n",
    "    most_similar_index = similarities.index(max(similarities))\n",
    "\n",
    "    # Check if similarity is above a certain threshold\n",
    "    if similarities[most_similar_index] > 0.41:  # Adjust threshold as needed\n",
    "        return all_data[most_similar_index][1]\n",
    "    else:\n",
    "        return \"I'm sorry, I don't have an answer to that. Please wait while I connect you to a real person.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d013c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function example (replace with your actual implementation)\n",
    "def preprocess_text(query):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = word_tokenize(query.lower())\n",
    "\n",
    "    words = [w for w in word_list if w not in stop_words]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dff379fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To finish the chat please type:\n",
      "\t exit or quit or goodbye or bye \n",
      "You: hey\n",
      "Chatbot: Hey\n",
      "You: How can I make a budget\n",
      "Chatbot: To make a budget, start by tracking your income and expenses. Then, allocate your income towards essential expenses like rent, food, and bills. Next, allocate some of your income towards savings and debt repayment. Finally, allocate the remainder of your income towards discretionary expenses like entertainment and hobbies.\n",
      "You: i need some inspiration\n",
      "Chatbot: You are capable of achieving remarkable things. Believe in yourself and never give up!\n",
      "You: how to save money\n",
      "Chatbot: Investing in stocks, mutual funds, or real estate can help grow your wealth over time.\n",
      "You: Tell me about effective decision-making and trusting intuition.\n",
      "Chatbot: Effective decision-making involves gathering information, weighing pros and cons, and considering the potential outcomes.\n",
      "You: ok\n",
      "Chatbot: is there anythins with which i can assist?\n",
      "You: bye\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download NLTK resources\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        try:\n",
    "            user_query = input(\"You: \")\n",
    "            if user_query.lower() in ['exit', 'quit', 'goodbye', 'bye']:\n",
    "                print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "                break\n",
    "            response = respond_to_query(user_query, all_data)\n",
    "            print(\"Chatbot:\", response)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChatbot: Bye! See you next time. (interrupted)\")\n",
    "            break\n",
    "        \n",
    "filename = \"intents_file.json\"  # Replace with your actual file name\n",
    "all_data = convert_data_to_tuples(filename)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"To finish the chat please type:\\n\\t exit or quit or goodbye or bye \")\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
